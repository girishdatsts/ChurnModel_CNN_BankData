{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification template\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('/Users/harpreet/Documents/C_A_ProjReq/C_A_SourceDB/Cfpb_ChurnModel/Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy of dataset into DF\n",
    "DF=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding categorical Data\n",
    "#Encoding Independent variables\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:,2] = labelencoder_X_2.fit_transform(X[:,2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:] #to prevent data duplicy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   2.28000000e+02,\n",
       "          0.00000000e+00,   4.20000000e+01,   2.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.01348880e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   2.17000000e+02,\n",
       "          0.00000000e+00,   4.10000000e+01,   1.00000000e+00,\n",
       "          8.38078600e+04,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   1.12542580e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.11000000e+02,\n",
       "          0.00000000e+00,   4.20000000e+01,   8.00000000e+00,\n",
       "          1.59660800e+05,   3.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   1.13931570e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   3.08000000e+02,\n",
       "          0.00000000e+00,   3.90000000e+01,   1.00000000e+00,\n",
       "          0.00000000e+00,   2.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   9.38266300e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   4.59000000e+02,\n",
       "          0.00000000e+00,   4.30000000e+01,   2.00000000e+00,\n",
       "          1.25510820e+05,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   7.90841000e+04]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   0.00000000e+00   5.97000000e+02 ...,   1.00000000e+00\n",
      "    1.00000000e+00   1.92852670e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   5.23000000e+02 ...,   1.00000000e+00\n",
      "    0.00000000e+00   1.28702100e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   7.06000000e+02 ...,   1.00000000e+00\n",
      "    1.00000000e+00   7.57322500e+04]\n",
      " ..., \n",
      " [  0.00000000e+00   1.00000000e+00   5.78000000e+02 ...,   1.00000000e+00\n",
      "    0.00000000e+00   1.41533190e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   6.50000000e+02 ...,   1.00000000e+00\n",
      "    1.00000000e+00   1.12764800e+04]\n",
      " [  1.00000000e+00   0.00000000e+00   5.73000000e+02 ...,   1.00000000e+00\n",
      "    0.00000000e+00   1.92950600e+05]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the ANN\n",
    "#Importing keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "#Initializing the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Adding input layer and first hidden layer with dropout\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dropout(p = 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Adding second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(p = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.4826 - acc: 0.7960\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 6s 734us/step - loss: 0.4364 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 6s 730us/step - loss: 0.4310 - acc: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 6s 737us/step - loss: 0.4292 - acc: 0.7960\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 6s 739us/step - loss: 0.4283 - acc: 0.7966\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 6s 739us/step - loss: 0.4261 - acc: 0.8167\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 6s 748us/step - loss: 0.4258 - acc: 0.8204\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 6s 746us/step - loss: 0.4252 - acc: 0.8225\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 6s 751us/step - loss: 0.4253 - acc: 0.8260\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 6s 750us/step - loss: 0.4275 - acc: 0.8234\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 6s 755us/step - loss: 0.4229 - acc: 0.8259\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 7s 819us/step - loss: 0.4223 - acc: 0.8269\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 7s 814us/step - loss: 0.4261 - acc: 0.8266\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 6s 803us/step - loss: 0.4234 - acc: 0.8279\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 6s 745us/step - loss: 0.4243 - acc: 0.8281\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 7s 818us/step - loss: 0.4230 - acc: 0.8286\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 6s 739us/step - loss: 0.4252 - acc: 0.8269\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 6s 717us/step - loss: 0.4239 - acc: 0.8275\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 6s 722us/step - loss: 0.4221 - acc: 0.8296\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 6s 724us/step - loss: 0.4248 - acc: 0.8281\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 6s 722us/step - loss: 0.4209 - acc: 0.8286\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 6s 718us/step - loss: 0.4237 - acc: 0.8270\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 6s 718us/step - loss: 0.4209 - acc: 0.8279\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 6s 738us/step - loss: 0.4225 - acc: 0.8281\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 6s 745us/step - loss: 0.4236 - acc: 0.8285\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 6s 741us/step - loss: 0.4238 - acc: 0.8309\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 6s 744us/step - loss: 0.4252 - acc: 0.8271\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 6s 742us/step - loss: 0.4198 - acc: 0.8284\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 6s 740us/step - loss: 0.4214 - acc: 0.8279\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 6s 730us/step - loss: 0.4201 - acc: 0.8312\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 6s 719us/step - loss: 0.4217 - acc: 0.8311\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 6s 741us/step - loss: 0.4220 - acc: 0.8315\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 6s 735us/step - loss: 0.4199 - acc: 0.8275\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 6s 730us/step - loss: 0.4194 - acc: 0.8289\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 6s 739us/step - loss: 0.4219 - acc: 0.8276\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 6s 727us/step - loss: 0.4230 - acc: 0.8285\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 6s 733us/step - loss: 0.4251 - acc: 0.8305\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 6s 734us/step - loss: 0.4209 - acc: 0.8310\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 6s 751us/step - loss: 0.4202 - acc: 0.8306\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 6s 740us/step - loss: 0.4182 - acc: 0.8322\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 6s 736us/step - loss: 0.4217 - acc: 0.8282\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 6s 751us/step - loss: 0.4209 - acc: 0.8280\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 6s 740us/step - loss: 0.4174 - acc: 0.8315\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 6s 733us/step - loss: 0.4199 - acc: 0.8306\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 6s 722us/step - loss: 0.4224 - acc: 0.8301\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 6s 704us/step - loss: 0.4204 - acc: 0.8289\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 6s 741us/step - loss: 0.4190 - acc: 0.8277\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 6s 748us/step - loss: 0.4188 - acc: 0.8300\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 6s 750us/step - loss: 0.4199 - acc: 0.8314\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 6s 748us/step - loss: 0.4224 - acc: 0.8304\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 6s 751us/step - loss: 0.4209 - acc: 0.8319\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 6s 713us/step - loss: 0.4228 - acc: 0.8276\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 6s 718us/step - loss: 0.4188 - acc: 0.8294\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 6s 733us/step - loss: 0.4202 - acc: 0.8294\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 6s 703us/step - loss: 0.4192 - acc: 0.8302\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 6s 729us/step - loss: 0.4209 - acc: 0.8292\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 6s 717us/step - loss: 0.4199 - acc: 0.8302\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 6s 738us/step - loss: 0.4208 - acc: 0.8275\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 6s 741us/step - loss: 0.4201 - acc: 0.8301\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 6s 731us/step - loss: 0.4193 - acc: 0.8315\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 6s 729us/step - loss: 0.4216 - acc: 0.8321\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 6s 718us/step - loss: 0.4195 - acc: 0.8295\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 6s 728us/step - loss: 0.4202 - acc: 0.8299\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 6s 727us/step - loss: 0.4190 - acc: 0.8320\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 6s 721us/step - loss: 0.4209 - acc: 0.8300\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 6s 734us/step - loss: 0.4219 - acc: 0.8327\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 6s 750us/step - loss: 0.4203 - acc: 0.8315\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 6s 746us/step - loss: 0.4192 - acc: 0.8311\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 6s 733us/step - loss: 0.4185 - acc: 0.8329\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 6s 767us/step - loss: 0.4185 - acc: 0.8331\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 6s 795us/step - loss: 0.4187 - acc: 0.8315\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 6s 728us/step - loss: 0.4214 - acc: 0.8319\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 7s 848us/step - loss: 0.4238 - acc: 0.8325\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 6s 802us/step - loss: 0.4201 - acc: 0.8316\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 6s 771us/step - loss: 0.4199 - acc: 0.8319\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 7s 850us/step - loss: 0.4169 - acc: 0.8312\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 6s 736us/step - loss: 0.4170 - acc: 0.8311\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 6s 758us/step - loss: 0.4219 - acc: 0.8312\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 6s 810us/step - loss: 0.4193 - acc: 0.8325\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 6s 800us/step - loss: 0.4216 - acc: 0.8309\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 7s 877us/step - loss: 0.4191 - acc: 0.8302\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 7s 866us/step - loss: 0.4171 - acc: 0.8339\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 7s 837us/step - loss: 0.4203 - acc: 0.8369\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 6s 720us/step - loss: 0.4170 - acc: 0.8330\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 6s 714us/step - loss: 0.4176 - acc: 0.8310\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 5s 682us/step - loss: 0.4199 - acc: 0.8307\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 5s 672us/step - loss: 0.4197 - acc: 0.8305\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 5s 676us/step - loss: 0.4162 - acc: 0.8314\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 5s 659us/step - loss: 0.4177 - acc: 0.8322\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 5s 657us/step - loss: 0.4194 - acc: 0.8340\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 5s 646us/step - loss: 0.4215 - acc: 0.8325\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 5s 652us/step - loss: 0.4176 - acc: 0.8334\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 5s 667us/step - loss: 0.4208 - acc: 0.8321\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 5s 657us/step - loss: 0.4192 - acc: 0.8322\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 5s 650us/step - loss: 0.4215 - acc: 0.8335\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 5s 656us/step - loss: 0.4184 - acc: 0.8321\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 5s 622us/step - loss: 0.4184 - acc: 0.8322\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 5s 673us/step - loss: 0.4181 - acc: 0.8326\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 5s 661us/step - loss: 0.4202 - acc: 0.8335\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 5s 653us/step - loss: 0.4199 - acc: 0.8345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3dd4ed68>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the ANN to the training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions and evaluating the models\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#homework\n",
    "new_prediction = classifier.predict(sc.transform(np.array([[0.0,0,600,1,40,3,60000,2,1,1,50000]])))\n",
    "new_prediction = (new_prediction > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1532,   63],\n",
       "       [ 234,  171]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 482us/step - loss: 0.4832 - acc: 0.7961\n",
      "800/800 [==============================] - 0s 151us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 438us/step - loss: 0.4936 - acc: 0.7961\n",
      "800/800 [==============================] - 0s 177us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 446us/step - loss: 0.5054 - acc: 0.7997\n",
      "800/800 [==============================] - 0s 197us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 442us/step - loss: 0.4875 - acc: 0.7972\n",
      "800/800 [==============================] - 0s 217us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 491us/step - loss: 0.4824 - acc: 0.7935\n",
      "800/800 [==============================] - 0s 253us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 458us/step - loss: 0.5010 - acc: 0.7949\n",
      "800/800 [==============================] - 0s 261us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 466us/step - loss: 0.4905 - acc: 0.7965\n",
      "800/800 [==============================] - 0s 278us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 483us/step - loss: 0.4898 - acc: 0.7960\n",
      "800/800 [==============================] - 0s 317us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 493us/step - loss: 0.5017 - acc: 0.7946\n",
      "800/800 [==============================] - 0s 328us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 492us/step - loss: 0.5001 - acc: 0.7961\n",
      "800/800 [==============================] - 0s 361us/step\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, nb_epoch = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = 1)\n",
    "#n_jobs = 1 due to using windows, for other platforms, use n_jobs = -1, to engage all the processors\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/Users/harpreet/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 259us/step - loss: 0.5647 - acc: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 254us/step - loss: 0.5648 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 255us/step - loss: 0.5970 - acc: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 255us/step - loss: 0.5601 - acc: 0.7963\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 266us/step - loss: 0.5718 - acc: 0.7915\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 267us/step - loss: 0.5560 - acc: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 278us/step - loss: 0.5748 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 284us/step - loss: 0.5559 - acc: 0.7963\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 297us/step - loss: 0.5612 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 291us/step - loss: 0.5540 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 263us/step - loss: 0.5942 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 284us/step - loss: 0.5659 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 289us/step - loss: 0.5773 - acc: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 294us/step - loss: 0.5746 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 290us/step - loss: 0.5886 - acc: 0.7919\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 302us/step - loss: 0.5750 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 305us/step - loss: 0.6087 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 307us/step - loss: 0.5676 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 323us/step - loss: 0.5571 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 319us/step - loss: 0.6054 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 346us/step - loss: 0.5748 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 358us/step - loss: 0.5613 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.5515 - acc: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 378us/step - loss: 0.5682 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 378us/step - loss: 0.5734 - acc: 0.7914\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 387us/step - loss: 0.5686 - acc: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 391us/step - loss: 0.5602 - acc: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 391us/step - loss: 0.5992 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 392us/step - loss: 0.5782 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 415us/step - loss: 0.5496 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 440us/step - loss: 0.6047 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 425us/step - loss: 0.5559 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 411us/step - loss: 0.5812 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 445us/step - loss: 0.5869 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 388us/step - loss: 0.6264 - acc: 0.7917\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 402us/step - loss: 0.6009 - acc: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 480us/step - loss: 0.5692 - acc: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 526us/step - loss: 0.5622 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 525us/step - loss: 0.5793 - acc: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 506us/step - loss: 0.5843 - acc: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 418us/step - loss: 0.5784 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 447us/step - loss: 0.6000 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 437us/step - loss: 0.5858 - acc: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 477us/step - loss: 0.5725 - acc: 0.7975\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 594us/step - loss: 0.5851 - acc: 0.7925\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 569us/step - loss: 0.6064 - acc: 0.7919\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 713us/step - loss: 0.5738 - acc: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 539us/step - loss: 0.6028 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 529us/step - loss: 0.5882 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 486us/step - loss: 0.5793 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 475us/step - loss: 0.5983 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 467us/step - loss: 0.6137 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 470us/step - loss: 0.6114 - acc: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 482us/step - loss: 0.6109 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 486us/step - loss: 0.6139 - acc: 0.7922\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 477us/step - loss: 0.5795 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 495us/step - loss: 0.5862 - acc: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 496us/step - loss: 0.6190 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 505us/step - loss: 0.6433 - acc: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 505us/step - loss: 0.5933 - acc: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 533us/step - loss: 0.5919 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 543us/step - loss: 0.6059 - acc: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 629us/step - loss: 0.5898 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 567us/step - loss: 0.5950 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 567us/step - loss: 0.5839 - acc: 0.7924\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 955us/step - loss: 0.5919 - acc: 0.7925\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 559us/step - loss: 0.5902 - acc: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 559us/step - loss: 0.5688 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 560us/step - loss: 0.5863 - acc: 0.7925\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 569us/step - loss: 0.5949 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 556us/step - loss: 0.5939 - acc: 0.7971\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 551us/step - loss: 0.6374 - acc: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 548us/step - loss: 0.6289 - acc: 0.7925\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 568us/step - loss: 0.5920 - acc: 0.7972\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 561us/step - loss: 0.5974 - acc: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 590us/step - loss: 0.6008 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 586us/step - loss: 0.5803 - acc: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 597us/step - loss: 0.6431 - acc: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 662us/step - loss: 0.5983 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 607us/step - loss: 0.6274 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 5s 680us/step - loss: 0.5339 - acc: 0.7960\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [25,32],\n",
    "              'nb_epoch': [100,500],\n",
    "              'optimizer': ['adam','rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################_Trying Diffrent Approach_#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that we have decided won't be used in prediction\n",
    "df = DF.drop([\"RowNumber\", \"Gender\"], axis=1)\n",
    "features = df.drop([\"Exited\"], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerId   Surname  CreditScore Geography  Age  Tenure    Balance  \\\n",
       "0    15634602  Hargrave          619    France   42       2       0.00   \n",
       "1    15647311      Hill          608     Spain   41       1   83807.86   \n",
       "2    15619304      Onio          502    France   42       8  159660.80   \n",
       "3    15701354      Boni          699    France   39       1       0.00   \n",
       "4    15737888  Mitchell          850     Spain   43       2  125510.82   \n",
       "\n",
       "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0              1          1               1        101348.88       1  \n",
       "1              1          0               1        112542.58       0  \n",
       "2              3          1               0        113931.57       1  \n",
       "3              2          0               0         93826.63       0  \n",
       "4              1          1               1         79084.10       0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42\n",
      " 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\n",
      " 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 88 92]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.unique(df['Age']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{18: 0, 19: 1, 20: 2, 21: 3, 22: 4, 23: 5, 24: 6, 25: 7, 26: 8, 27: 9, 28: 10, 29: 11, 30: 12, 31: 13, 32: 14, 33: 15, 34: 16, 35: 17, 36: 18, 37: 19, 38: 20, 39: 21, 40: 22, 41: 23, 42: 24, 43: 25, 44: 26, 45: 27, 46: 28, 47: 29, 48: 30, 49: 31, 50: 32, 51: 33, 52: 34, 53: 35, 54: 36, 55: 37, 56: 38, 57: 39, 58: 40, 59: 41, 60: 42, 61: 43, 62: 44, 63: 45, 64: 46, 65: 47, 66: 48, 67: 49, 68: 50, 69: 51, 70: 52, 71: 53, 72: 54, 73: 55, 74: 56, 75: 57, 76: 58, 77: 59, 78: 60, 79: 61, 80: 62, 81: 63, 82: 64, 83: 65, 84: 66, 85: 67, 88: 68, 92: 69}\n"
     ]
    }
   ],
   "source": [
    "#print np.unique(data['Age Band'])  \n",
    "#[0 999 u'0-17' u'18-34' u'35-54' u'55+']\n",
    "df['Age'].replace(999,0,inplace=True)\n",
    "agefeaturemap = {label:idx for idx,label in enumerate(np.unique(df['Age']))}\n",
    "print (agefeaturemap)\n",
    "df['Age'] = df['Age'].map(agefeaturemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350 351 358 359 363 365 367 373 376 382 383 386 395 399 401 404 405 407\n",
      " 408 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426\n",
      " 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444\n",
      " 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462\n",
      " 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480\n",
      " 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498\n",
      " 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516\n",
      " 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534\n",
      " 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552\n",
      " 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570\n",
      " 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588\n",
      " 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606\n",
      " 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624\n",
      " 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642\n",
      " 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660\n",
      " 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678\n",
      " 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696\n",
      " 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714\n",
      " 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732\n",
      " 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750\n",
      " 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768\n",
      " 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786\n",
      " 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804\n",
      " 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822\n",
      " 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840\n",
      " 841 842 843 844 845 846 847 848 849 850]\n",
      "{350: 0, 351: 1, 358: 2, 359: 3, 363: 4, 365: 5, 367: 6, 373: 7, 376: 8, 382: 9, 383: 10, 386: 11, 395: 12, 399: 13, 401: 14, 404: 15, 405: 16, 407: 17, 408: 18, 410: 19, 411: 20, 412: 21, 413: 22, 414: 23, 415: 24, 416: 25, 417: 26, 418: 27, 419: 28, 420: 29, 421: 30, 422: 31, 423: 32, 424: 33, 425: 34, 426: 35, 427: 36, 428: 37, 429: 38, 430: 39, 431: 40, 432: 41, 433: 42, 434: 43, 435: 44, 436: 45, 437: 46, 438: 47, 439: 48, 440: 49, 441: 50, 442: 51, 443: 52, 444: 53, 445: 54, 446: 55, 447: 56, 448: 57, 449: 58, 450: 59, 451: 60, 452: 61, 453: 62, 454: 63, 455: 64, 456: 65, 457: 66, 458: 67, 459: 68, 460: 69, 461: 70, 462: 71, 463: 72, 464: 73, 465: 74, 466: 75, 467: 76, 468: 77, 469: 78, 470: 79, 471: 80, 472: 81, 473: 82, 474: 83, 475: 84, 476: 85, 477: 86, 478: 87, 479: 88, 480: 89, 481: 90, 482: 91, 483: 92, 484: 93, 485: 94, 486: 95, 487: 96, 488: 97, 489: 98, 490: 99, 491: 100, 492: 101, 493: 102, 494: 103, 495: 104, 496: 105, 497: 106, 498: 107, 499: 108, 500: 109, 501: 110, 502: 111, 503: 112, 504: 113, 505: 114, 506: 115, 507: 116, 508: 117, 509: 118, 510: 119, 511: 120, 512: 121, 513: 122, 514: 123, 515: 124, 516: 125, 517: 126, 518: 127, 519: 128, 520: 129, 521: 130, 522: 131, 523: 132, 524: 133, 525: 134, 526: 135, 527: 136, 528: 137, 529: 138, 530: 139, 531: 140, 532: 141, 533: 142, 534: 143, 535: 144, 536: 145, 537: 146, 538: 147, 539: 148, 540: 149, 541: 150, 542: 151, 543: 152, 544: 153, 545: 154, 546: 155, 547: 156, 548: 157, 549: 158, 550: 159, 551: 160, 552: 161, 553: 162, 554: 163, 555: 164, 556: 165, 557: 166, 558: 167, 559: 168, 560: 169, 561: 170, 562: 171, 563: 172, 564: 173, 565: 174, 566: 175, 567: 176, 568: 177, 569: 178, 570: 179, 571: 180, 572: 181, 573: 182, 574: 183, 575: 184, 576: 185, 577: 186, 578: 187, 579: 188, 580: 189, 581: 190, 582: 191, 583: 192, 584: 193, 585: 194, 586: 195, 587: 196, 588: 197, 589: 198, 590: 199, 591: 200, 592: 201, 593: 202, 594: 203, 595: 204, 596: 205, 597: 206, 598: 207, 599: 208, 600: 209, 601: 210, 602: 211, 603: 212, 604: 213, 605: 214, 606: 215, 607: 216, 608: 217, 609: 218, 610: 219, 611: 220, 612: 221, 613: 222, 614: 223, 615: 224, 616: 225, 617: 226, 618: 227, 619: 228, 620: 229, 621: 230, 622: 231, 623: 232, 624: 233, 625: 234, 626: 235, 627: 236, 628: 237, 629: 238, 630: 239, 631: 240, 632: 241, 633: 242, 634: 243, 635: 244, 636: 245, 637: 246, 638: 247, 639: 248, 640: 249, 641: 250, 642: 251, 643: 252, 644: 253, 645: 254, 646: 255, 647: 256, 648: 257, 649: 258, 650: 259, 651: 260, 652: 261, 653: 262, 654: 263, 655: 264, 656: 265, 657: 266, 658: 267, 659: 268, 660: 269, 661: 270, 662: 271, 663: 272, 664: 273, 665: 274, 666: 275, 667: 276, 668: 277, 669: 278, 670: 279, 671: 280, 672: 281, 673: 282, 674: 283, 675: 284, 676: 285, 677: 286, 678: 287, 679: 288, 680: 289, 681: 290, 682: 291, 683: 292, 684: 293, 685: 294, 686: 295, 687: 296, 688: 297, 689: 298, 690: 299, 691: 300, 692: 301, 693: 302, 694: 303, 695: 304, 696: 305, 697: 306, 698: 307, 699: 308, 700: 309, 701: 310, 702: 311, 703: 312, 704: 313, 705: 314, 706: 315, 707: 316, 708: 317, 709: 318, 710: 319, 711: 320, 712: 321, 713: 322, 714: 323, 715: 324, 716: 325, 717: 326, 718: 327, 719: 328, 720: 329, 721: 330, 722: 331, 723: 332, 724: 333, 725: 334, 726: 335, 727: 336, 728: 337, 729: 338, 730: 339, 731: 340, 732: 341, 733: 342, 734: 343, 735: 344, 736: 345, 737: 346, 738: 347, 739: 348, 740: 349, 741: 350, 742: 351, 743: 352, 744: 353, 745: 354, 746: 355, 747: 356, 748: 357, 749: 358, 750: 359, 751: 360, 752: 361, 753: 362, 754: 363, 755: 364, 756: 365, 757: 366, 758: 367, 759: 368, 760: 369, 761: 370, 762: 371, 763: 372, 764: 373, 765: 374, 766: 375, 767: 376, 768: 377, 769: 378, 770: 379, 771: 380, 772: 381, 773: 382, 774: 383, 775: 384, 776: 385, 777: 386, 778: 387, 779: 388, 780: 389, 781: 390, 782: 391, 783: 392, 784: 393, 785: 394, 786: 395, 787: 396, 788: 397, 789: 398, 790: 399, 791: 400, 792: 401, 793: 402, 794: 403, 795: 404, 796: 405, 797: 406, 798: 407, 799: 408, 800: 409, 801: 410, 802: 411, 803: 412, 804: 413, 805: 414, 806: 415, 807: 416, 808: 417, 809: 418, 810: 419, 811: 420, 812: 421, 813: 422, 814: 423, 815: 424, 816: 425, 817: 426, 818: 427, 819: 428, 820: 429, 821: 430, 822: 431, 823: 432, 824: 433, 825: 434, 826: 435, 827: 436, 828: 437, 829: 438, 830: 439, 831: 440, 832: 441, 833: 442, 834: 443, 835: 444, 836: 445, 837: 446, 838: 447, 839: 448, 840: 449, 841: 450, 842: 451, 843: 452, 844: 453, 845: 454, 846: 455, 847: 456, 848: 457, 849: 458, 850: 459}\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(df['CreditScore']) )\n",
    "#[0 u'300-553' u'554-602' u'603-640' u'641-685' u'686-733' u'734-850']\n",
    "creditscoremap = {label:idx for idx,label in enumerate(np.unique(df['CreditScore']))}\n",
    "print(creditscoremap)\n",
    "df['CreditScore'] = df['CreditScore'].map(creditscoremap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459]\n"
     ]
    }
   ],
   "source": [
    "print( np.unique(df['CreditScore']) )\n",
    "#[0 u'300-553' u'554-602' u'603-640' u'641-685' u'686-733' u'734-850']\n",
    "df['CreditScore'] = df['CreditScore'].map(creditscoremap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.75486502 -0.57369368 -0.55204276 ...,  0.64259497  0.9687384\n",
      "   1.61085707]\n",
      " [-0.5698444  -0.57369368 -1.31490297 ...,  0.64259497 -1.03227043\n",
      "   0.49587037]\n",
      " [-0.5698444   1.74309049  0.57162971 ...,  0.64259497  0.9687384\n",
      "  -0.42478674]\n",
      " ..., \n",
      " [-0.5698444   1.74309049 -0.74791227 ...,  0.64259497 -1.03227043\n",
      "   0.71888467]\n",
      " [ 1.75486502 -0.57369368 -0.00566991 ...,  0.64259497  0.9687384\n",
      "  -1.54507805]\n",
      " [ 1.75486502 -0.57369368 -0.79945688 ...,  0.64259497 -1.03227043\n",
      "   1.61255917]] [[False]\n",
      " [False]\n",
      " [False]\n",
      " ..., \n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
